{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base MLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80000, 310)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import ensemble, linear_model\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from utils.metrics import Metric\n",
    "from tqdm import tqdm\n",
    "weights = pd.read_csv('data/005_weights.csv')['weight'].values\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "X_submit = pd.read_csv('./data/420_X_submit.csv', index_col='id')\n",
    "X_train = pd.read_csv('./data/420_X_train.csv', index_col='id')\n",
    "X_test = pd.read_csv('./data/420_X_test.csv', index_col='id')\n",
    "\n",
    "y_submit = pd.read_csv('./data/004_test.csv', index_col='id')\n",
    "y_train = pd.read_csv('./data/410_y_train.csv', index_col='id')\n",
    "y_test = pd.read_csv('./data/410_y_test.csv', index_col='id')\n",
    "\n",
    "X_submit = X_submit.values\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = np.squeeze(y_train.values)\n",
    "y_test = np.squeeze(y_test.values)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:16, 45.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8406305364035296\n",
      "CPU times: user 3h 38min 19s, sys: 1min 46s, total: 3h 40min 6s\n",
      "Wall time: 4min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_1 = CatBoostClassifier(iterations=1000,\n",
    "                           depth=2,\n",
    "                           learning_rate=1,\n",
    "                           loss_function='MultiClass',\n",
    "                           random_seed=100,\n",
    "                           verbose=False)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "skf.get_n_splits(X_train, y_train)\n",
    "\n",
    "y_train_pred_1 = []\n",
    "for train_index, test_index in tqdm(skf.split(X_train, y_train)):\n",
    "    xt, xv = X_train[train_index], X_train[test_index]\n",
    "    yt, yv = y_train[train_index], y_train[test_index]\n",
    "    # train the model\n",
    "    model_1.fit(xt, yt, eval_set=(xv, yv), early_stopping_rounds=30)\n",
    "    y_train_pred_1.append(model_1.predict_proba(xv))\n",
    "    \n",
    "y_train_pred_1 = np.concatenate(y_train_pred_1)\n",
    "print(metrics.log_loss(y_train, y_train_pred_1))\n",
    "model_1.fit(X_train, y_train)\n",
    "y_test_pred_1   = model_1.predict_proba(X_test)\n",
    "y_submit_pred_1 = model_1.predict_proba(X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3429361670810729\n",
      "CPU times: user 1h 27min 28s, sys: 5.53 s, total: 1h 27min 33s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_2 = XGBClassifier(\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    verbosity=1,\n",
    "    silent=None,\n",
    "    objective='multi:softmax',\n",
    "    booster='gbtree',\n",
    "    eval_metric='mlogloss',\n",
    "    n_jobs=36,\n",
    "    nthread=36,\n",
    "    gamma=5,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=0.5,\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=100,\n",
    "    seed=None,\n",
    "    missing=None,\n",
    "    importance_type='gain'\n",
    ")\n",
    "\n",
    "y_train_pred_2  = cross_val_predict(model_2, X_train, y_train, cv=3, method='predict_proba')\n",
    "print(metrics.log_loss(y_train, y_train_pred_2))\n",
    "model_2.fit(X_train, y_train)\n",
    "y_test_pred_2   = model_2.predict_proba(X_test)\n",
    "y_submit_pred_2 = model_2.predict_proba(X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.606489195361814\n",
      "CPU times: user 3min 54s, sys: 4.69 s, total: 3min 59s\n",
      "Wall time: 43.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_3 = ensemble.RandomForestClassifier(n_estimators=200, max_depth=4, max_features=0.4, n_jobs=36, random_state=100)\n",
    "\n",
    "y_train_pred_3  = cross_val_predict(model_3, X_train, y_train, cv=3, method='predict_proba')\n",
    "print(metrics.log_loss(y_train, y_train_pred_3))\n",
    "model_3.fit(X_train, y_train)\n",
    "y_test_pred_3   = model_3.predict_proba(X_test)\n",
    "y_submit_pred_3 = model_3.predict_proba(X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5479847591245361\n",
      "CPU times: user 10min 39s, sys: 4.29 s, total: 10min 43s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_4 = ensemble.RandomForestClassifier(n_estimators=300, max_depth=6, max_features=0.5, n_jobs=36, random_state=100)\n",
    "\n",
    "y_train_pred_4  = cross_val_predict(model_4, X_train, y_train, cv=3, method='predict_proba')\n",
    "print(metrics.log_loss(y_train, y_train_pred_4))\n",
    "model_4.fit(X_train, y_train)\n",
    "y_test_pred_4   = model_4.predict_proba(X_test)\n",
    "y_submit_pred_4 = model_4.predict_proba(X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3268524651420768\n",
      "CPU times: user 1h 21min 20s, sys: 4.57 s, total: 1h 21min 24s\n",
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_5 = XGBClassifier(\n",
    "    max_depth=3,\n",
    "    learning_rate=0.3,\n",
    "    n_estimators=100,\n",
    "    verbosity=1,\n",
    "    silent=None,\n",
    "    objective='multi:softmax',\n",
    "    booster='gbtree',\n",
    "    eval_metric='mlogloss',\n",
    "    n_jobs=40,\n",
    "    nthread=40,\n",
    "    gamma=1,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=0.5,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=0.7,\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=100,\n",
    "    seed=None,\n",
    "    missing=None,\n",
    "    importance_type='gain'\n",
    ")\n",
    "\n",
    "y_train_pred_5  = cross_val_predict(model_5, X_train, y_train, cv=3, method='predict_proba')\n",
    "print(metrics.log_loss(y_train, y_train_pred_5))\n",
    "model_5.fit(X_train, y_train)\n",
    "y_test_pred_5   = model_5.predict_proba(X_test)\n",
    "y_submit_pred_5 = model_5.predict_proba(X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2983929338992457\n",
      "CPU times: user 1h 20min 18s, sys: 4.33 s, total: 1h 20min 23s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_6 = XGBClassifier(\n",
    "    max_depth=4,\n",
    "    learning_rate=0.3,\n",
    "    n_estimators=100,\n",
    "    verbosity=1,\n",
    "    silent=None,\n",
    "    objective='reg:logistic',\n",
    "    eval_metric='merror',\n",
    "    booster='gbtree',\n",
    "    n_jobs=40,\n",
    "    nthread=40,\n",
    "    gamma=1,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=0.6,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=0.5,\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=100,\n",
    "    seed=None,\n",
    "    missing=None,\n",
    "    importance_type='gain'\n",
    ")\n",
    "\n",
    "y_train_pred_6  = cross_val_predict(model_6, X_train, y_train, cv=3, method='predict_proba')\n",
    "print(metrics.log_loss(y_train, y_train_pred_6))\n",
    "model_6.fit(X_train, y_train)\n",
    "y_test_pred_6   = model_6.predict_proba(X_test)\n",
    "y_submit_pred_6 = model_6.predict_proba(X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80000, 65), (20000, 65), (53240, 65))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preds = np.concatenate([\n",
    "#     y_train_pred_1,\n",
    "    y_train_pred_2,\n",
    "    y_train_pred_3,\n",
    "    y_train_pred_4,\n",
    "    y_train_pred_5,\n",
    "    y_train_pred_6\n",
    "], axis=1)\n",
    "\n",
    "\n",
    "X_test_preds = np.concatenate([\n",
    "#     y_test_pred_1,\n",
    "    y_test_pred_2,\n",
    "    y_test_pred_3,\n",
    "    y_test_pred_4,\n",
    "    y_test_pred_5,\n",
    "    y_test_pred_6\n",
    "], axis=1)\n",
    "\n",
    "X_submit_preds = np.concatenate([\n",
    "#     y_submit_pred_1,\n",
    "    y_submit_pred_2,\n",
    "    y_submit_pred_3,\n",
    "    y_submit_pred_4,\n",
    "    y_submit_pred_5,\n",
    "    y_submit_pred_6\n",
    "], axis=1)\n",
    "\n",
    "X_train_preds.shape, X_test_preds.shape, X_submit_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153240, 65)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tmp = np.concatenate((\n",
    "    X_train_preds,\n",
    "    X_test_preds,\n",
    "    X_submit_preds\n",
    "), axis=0)\n",
    "\n",
    "X_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "qt = QuantileTransformer(n_quantiles=10, random_state=100, output_distribution='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt.fit(X_tmp)\n",
    "\n",
    "X_train_preds  = qt.transform(X_train_preds)\n",
    "X_test_preds   = qt.transform(X_test_preds)\n",
    "X_submit_preds = qt.transform(X_submit_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M_336/520_base_ml_qt_normal.joblib']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model_1, 'M_336/520_base_ml_model_1.joblib')\n",
    "dump(model_2, 'M_336/520_base_ml_model_2.joblib')\n",
    "dump(model_3, 'M_336/520_base_ml_model_3.joblib')\n",
    "dump(model_4, 'M_336/520_base_ml_model_4.joblib')\n",
    "dump(model_5, 'M_336/520_base_ml_model_5.joblib')\n",
    "dump(model_6, 'M_336/520_base_ml_model_6.joblib')\n",
    "\n",
    "dump(qt, 'M_336/520_base_ml_qt_normal.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data/520_X_train_preds.csv' , X_train_preds , delimiter=\",\")\n",
    "np.savetxt('data/520_X_test_preds.csv'  , X_test_preds  , delimiter=\",\")\n",
    "np.savetxt('data/520_X_submit_preds.csv', X_submit_preds, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
