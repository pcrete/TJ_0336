{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base MLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 280)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import ensemble, linear_model\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from utils.metrics import Metric\n",
    "from tqdm import tqdm\n",
    "weights = pd.read_csv('data/005_weights.csv')['weight'].values\n",
    "\n",
    "\n",
    "X_submit = pd.read_csv('./data/410_X_submit.csv', index_col='id')\n",
    "X_train = pd.read_csv('./data/410_X_train.csv', index_col='id')\n",
    "X_test = pd.read_csv('./data/410_X_test.csv', index_col='id')\n",
    "\n",
    "y_submit = pd.read_csv('./data/004_test.csv', index_col='id')\n",
    "y_train = pd.read_csv('./data/410_y_train.csv', index_col='id')\n",
    "y_test = pd.read_csv('./data/410_y_test.csv', index_col='id')\n",
    "\n",
    "X_submit = X_submit.values\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = np.squeeze(y_train.values)\n",
    "y_test = np.squeeze(y_test.values)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3804222034256206\n",
      "CPU times: user 1h 16min 12s, sys: 4.32 s, total: 1h 16min 16s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_1 = XGBClassifier(\n",
    "    max_depth=4,\n",
    "    learning_rate=0.3,\n",
    "    n_estimators=100,\n",
    "    verbosity=1,\n",
    "    silent=None,\n",
    "    objective='reg:logistic',\n",
    "    eval_metric='mlogloss',\n",
    "    booster='gbtree',\n",
    "    n_jobs=40,\n",
    "    nthread=40,\n",
    "    gamma=1,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=0.6,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=0.5,\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=100,\n",
    "    seed=None,\n",
    "    missing=None,\n",
    "    importance_type='gain'\n",
    ")\n",
    "\n",
    "y_train_pred_1  = cross_val_predict(model_1, X_train, y_train, cv=3, method='predict_proba')\n",
    "print(metrics.log_loss(y_train, y_train_pred_1))\n",
    "model_1.fit(X_train, y_train)\n",
    "y_test_pred_1   = model_1.predict_proba(X_test)\n",
    "y_submit_pred_1 = model_1.predict_proba(X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4161252554443664\n",
      "CPU times: user 3h 9min 56s, sys: 17.6 s, total: 3h 10min 14s\n",
      "Wall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_2 = XGBClassifier(\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    verbosity=1,\n",
    "    silent=None,\n",
    "    objective='multi:softmax',\n",
    "    booster='gbtree',\n",
    "    eval_metric='mlogloss',\n",
    "    n_jobs=-1,\n",
    "    nthread=-1,\n",
    "    gamma=5,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=0.5,\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=100,\n",
    "    seed=None,\n",
    "    missing=None,\n",
    "    importance_type='gain'\n",
    ")\n",
    "\n",
    "y_train_pred_2  = cross_val_predict(model_2, X_train, y_train, cv=3, method='predict_proba')\n",
    "print(metrics.log_loss(y_train, y_train_pred_2))\n",
    "model_2.fit(X_train, y_train)\n",
    "y_test_pred_2   = model_2.predict_proba(X_test)\n",
    "y_submit_pred_2 = model_2.predict_proba(X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.644515654040536\n",
      "CPU times: user 6min 11s, sys: 8.38 s, total: 6min 20s\n",
      "Wall time: 52.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_3 = ensemble.RandomForestClassifier(n_estimators=200, max_depth=4, max_features=0.4, n_jobs=-1, random_state=100)\n",
    "\n",
    "y_train_pred_3  = cross_val_predict(model_3, X_train, y_train, cv=3, method='predict_proba')\n",
    "print(metrics.log_loss(y_train, y_train_pred_3))\n",
    "model_3.fit(X_train, y_train)\n",
    "y_test_pred_3   = model_3.predict_proba(X_test)\n",
    "y_submit_pred_3 = model_3.predict_proba(X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6001131929267354\n",
      "CPU times: user 18min 43s, sys: 9.23 s, total: 18min 52s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_4 = ensemble.RandomForestClassifier(n_estimators=300, max_depth=6, max_features=0.5, n_jobs=-1, random_state=100)\n",
    "\n",
    "y_train_pred_4  = cross_val_predict(model_4, X_train, y_train, cv=3, method='predict_proba',)\n",
    "print(metrics.log_loss(y_train, y_train_pred_4))\n",
    "model_4.fit(X_train, y_train)\n",
    "y_test_pred_4   = model_4.predict_proba(X_test)\n",
    "y_submit_pred_4 = model_4.predict_proba(X_submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80000, 52), (20000, 52), (53240, 52))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preds = np.concatenate([\n",
    "    y_train_pred_1,\n",
    "    y_train_pred_2,\n",
    "    y_train_pred_3,\n",
    "    y_train_pred_4\n",
    "], axis=1)\n",
    "\n",
    "\n",
    "X_test_preds = np.concatenate([\n",
    "    y_test_pred_1,\n",
    "    y_test_pred_2,\n",
    "    y_test_pred_3,\n",
    "    y_test_pred_4\n",
    "], axis=1)\n",
    "\n",
    "X_submit_preds = np.concatenate([\n",
    "    y_submit_pred_1,\n",
    "    y_submit_pred_2,\n",
    "    y_submit_pred_3,\n",
    "    y_submit_pred_4\n",
    "], axis=1)\n",
    "\n",
    "X_train_preds.shape, X_test_preds.shape, X_submit_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153240, 52)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tmp = np.concatenate((\n",
    "    X_train_preds,\n",
    "    X_test_preds,\n",
    "    X_submit_preds\n",
    "), axis=0)\n",
    "\n",
    "X_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "qt = QuantileTransformer(n_quantiles=10, random_state=100, output_distribution='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt.fit(X_tmp)\n",
    "\n",
    "X_train_preds  = qt.transform(X_train_preds)\n",
    "X_test_preds   = qt.transform(X_test_preds)\n",
    "X_submit_preds = qt.transform(X_submit_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M_336/510_base_ml_qt_normal.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model_1, 'M_336/510_base_ml_model_1.joblib')\n",
    "dump(model_2, 'M_336/510_base_ml_model_2.joblib')\n",
    "dump(model_3, 'M_336/510_base_ml_model_3.joblib')\n",
    "dump(model_4, 'M_336/510_base_ml_model_4.joblib')\n",
    "\n",
    "dump(qt, 'M_336/510_base_ml_qt_normal.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data/510_X_train_preds.csv' , X_train_preds , delimiter=\",\")\n",
    "np.savetxt('data/510_X_test_preds.csv'  , X_test_preds  , delimiter=\",\")\n",
    "np.savetxt('data/510_X_submit_preds.csv', X_submit_preds, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
