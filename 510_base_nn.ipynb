{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils.Block import Model\n",
    "from utils.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([64, 64], 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import ensemble, linear_model\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "X_submit = pd.read_csv('./data/420_X_submit.csv', index_col='id')\n",
    "X_train = pd.read_csv('./data/420_X_train.csv', index_col='id')\n",
    "X_test = pd.read_csv('./data/420_X_test.csv', index_col='id')\n",
    "\n",
    "y_submit = pd.read_csv('./data/004_test.csv', index_col='id')\n",
    "y_train = pd.read_csv('./data/410_y_train.csv', index_col='id')\n",
    "y_test = pd.read_csv('./data/410_y_test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = pd.read_csv('./data/003_train.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_w = class_weight.compute_class_weight('balanced', np.unique(y_), y_.values.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.11321385e+01, 3.53182171e+00, 3.47722073e-01, 2.81728234e-01,\n",
       "       4.32613896e-01, 1.92307692e+03, 8.07167649e+00, 1.02019996e+01,\n",
       "       4.61723151e+00, 1.10521662e+01, 4.00224126e-01, 3.68053000e+01,\n",
       "       1.19780562e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train['label'])\n",
    "y_test = pd.get_dummies(y_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 310)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_submit = X_submit.values\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = np.squeeze(y_train.values)\n",
    "y_test = np.squeeze(y_test.values)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(X_train, dtype='float64')\n",
    "y_train = tf.convert_to_tensor(y_train, dtype='float64')\n",
    "X_test  = tf.convert_to_tensor(X_test, dtype='float64')\n",
    "y_test  = tf.convert_to_tensor(y_test, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer block_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch: 0 \t training_losses: 0.3784887810788659 \t testing_losses: 0.5341817132390153\n",
      "Epoch: 20 \t training_losses: 0.22029801278136926 \t testing_losses: 0.28010288696008817\n",
      "Epoch: 40 \t training_losses: 0.20795134582564714 \t testing_losses: 0.28897003684359673\n",
      "early stopping\n"
     ]
    }
   ],
   "source": [
    "model = train(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '510_stack_nn'\n",
    "model.save_weights('M_336/checkpoints/'+model_name+'/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pred   = np.squeeze(np.array(model(X_test)))\n",
    "X_submit_pred = np.squeeze(np.array(model(X_submit)))\n",
    "\n",
    "X_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class0</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>class6</th>\n",
       "      <th>class7</th>\n",
       "      <th>class8</th>\n",
       "      <th>class9</th>\n",
       "      <th>class10</th>\n",
       "      <th>class11</th>\n",
       "      <th>class12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021627</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>0.065777</td>\n",
       "      <td>0.124921</td>\n",
       "      <td>0.044512</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.048683</td>\n",
       "      <td>0.051649</td>\n",
       "      <td>0.077450</td>\n",
       "      <td>0.074571</td>\n",
       "      <td>0.275773</td>\n",
       "      <td>0.032790</td>\n",
       "      <td>0.158495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.063774</td>\n",
       "      <td>0.112211</td>\n",
       "      <td>0.138676</td>\n",
       "      <td>0.087546</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.055819</td>\n",
       "      <td>0.417896</td>\n",
       "      <td>0.052942</td>\n",
       "      <td>0.036014</td>\n",
       "      <td>0.018985</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008781</td>\n",
       "      <td>0.060230</td>\n",
       "      <td>0.217216</td>\n",
       "      <td>0.181244</td>\n",
       "      <td>0.162623</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.042537</td>\n",
       "      <td>0.167549</td>\n",
       "      <td>0.043226</td>\n",
       "      <td>0.035115</td>\n",
       "      <td>0.053229</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.013165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006011</td>\n",
       "      <td>0.134851</td>\n",
       "      <td>0.149127</td>\n",
       "      <td>0.139214</td>\n",
       "      <td>0.131760</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.078139</td>\n",
       "      <td>0.203856</td>\n",
       "      <td>0.063280</td>\n",
       "      <td>0.042052</td>\n",
       "      <td>0.021489</td>\n",
       "      <td>0.023419</td>\n",
       "      <td>0.006669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085706</td>\n",
       "      <td>0.142549</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.116376</td>\n",
       "      <td>0.091587</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.084573</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.060298</td>\n",
       "      <td>0.067366</td>\n",
       "      <td>0.098988</td>\n",
       "      <td>0.085695</td>\n",
       "      <td>0.034170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class0    class1    class2    class3    class4    class5    class6  \\\n",
       "0  0.021627  0.023334  0.065777  0.124921  0.044512  0.000417  0.048683   \n",
       "1  0.001412  0.063774  0.112211  0.138676  0.087546  0.000054  0.055819   \n",
       "2  0.008781  0.060230  0.217216  0.181244  0.162623  0.001515  0.042537   \n",
       "3  0.006011  0.134851  0.149127  0.139214  0.131760  0.000134  0.078139   \n",
       "4  0.085706  0.142549  0.124000  0.116376  0.091587  0.000119  0.084573   \n",
       "\n",
       "     class7    class8    class9   class10   class11   class12  \n",
       "0  0.051649  0.077450  0.074571  0.275773  0.032790  0.158495  \n",
       "1  0.417896  0.052942  0.036014  0.018985  0.009312  0.005359  \n",
       "2  0.167549  0.043226  0.035115  0.053229  0.013571  0.013165  \n",
       "3  0.203856  0.063280  0.042052  0.021489  0.023419  0.006669  \n",
       "4  0.008571  0.060298  0.067366  0.098988  0.085695  0.034170  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit = pd.DataFrame.from_records(tf.nn.softmax(X_submit_pred).numpy())\n",
    "\n",
    "cols = ['class'+str(i) for i in range(13)]\n",
    "\n",
    "df_submit.columns = cols\n",
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class0</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>class6</th>\n",
       "      <th>class7</th>\n",
       "      <th>class8</th>\n",
       "      <th>class9</th>\n",
       "      <th>class10</th>\n",
       "      <th>class11</th>\n",
       "      <th>class12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151807</th>\n",
       "      <td>0.021627</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>0.065777</td>\n",
       "      <td>0.124921</td>\n",
       "      <td>0.044512</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.048683</td>\n",
       "      <td>0.051649</td>\n",
       "      <td>0.077450</td>\n",
       "      <td>0.074571</td>\n",
       "      <td>0.275773</td>\n",
       "      <td>0.032790</td>\n",
       "      <td>0.158495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118131</th>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.063774</td>\n",
       "      <td>0.112211</td>\n",
       "      <td>0.138676</td>\n",
       "      <td>0.087546</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.055819</td>\n",
       "      <td>0.417896</td>\n",
       "      <td>0.052942</td>\n",
       "      <td>0.036014</td>\n",
       "      <td>0.018985</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110921</th>\n",
       "      <td>0.008781</td>\n",
       "      <td>0.060230</td>\n",
       "      <td>0.217216</td>\n",
       "      <td>0.181244</td>\n",
       "      <td>0.162623</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.042537</td>\n",
       "      <td>0.167549</td>\n",
       "      <td>0.043226</td>\n",
       "      <td>0.035115</td>\n",
       "      <td>0.053229</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.013165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105149</th>\n",
       "      <td>0.006011</td>\n",
       "      <td>0.134851</td>\n",
       "      <td>0.149127</td>\n",
       "      <td>0.139214</td>\n",
       "      <td>0.131760</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.078139</td>\n",
       "      <td>0.203856</td>\n",
       "      <td>0.063280</td>\n",
       "      <td>0.042052</td>\n",
       "      <td>0.021489</td>\n",
       "      <td>0.023419</td>\n",
       "      <td>0.006669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143868</th>\n",
       "      <td>0.085706</td>\n",
       "      <td>0.142549</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.116376</td>\n",
       "      <td>0.091587</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.084573</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.060298</td>\n",
       "      <td>0.067366</td>\n",
       "      <td>0.098988</td>\n",
       "      <td>0.085695</td>\n",
       "      <td>0.034170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146316</th>\n",
       "      <td>0.015957</td>\n",
       "      <td>0.115297</td>\n",
       "      <td>0.093594</td>\n",
       "      <td>0.102673</td>\n",
       "      <td>0.103073</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.077883</td>\n",
       "      <td>0.078376</td>\n",
       "      <td>0.081684</td>\n",
       "      <td>0.133270</td>\n",
       "      <td>0.072542</td>\n",
       "      <td>0.088998</td>\n",
       "      <td>0.036518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121816</th>\n",
       "      <td>0.155807</td>\n",
       "      <td>0.013082</td>\n",
       "      <td>0.351903</td>\n",
       "      <td>0.129099</td>\n",
       "      <td>0.191808</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>0.133633</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>0.005022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106217</th>\n",
       "      <td>0.039621</td>\n",
       "      <td>0.199656</td>\n",
       "      <td>0.211499</td>\n",
       "      <td>0.118088</td>\n",
       "      <td>0.196356</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.057648</td>\n",
       "      <td>0.009684</td>\n",
       "      <td>0.031820</td>\n",
       "      <td>0.034603</td>\n",
       "      <td>0.031910</td>\n",
       "      <td>0.063821</td>\n",
       "      <td>0.005244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103515</th>\n",
       "      <td>0.091429</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>0.058322</td>\n",
       "      <td>0.106148</td>\n",
       "      <td>0.045634</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.076015</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.070956</td>\n",
       "      <td>0.103100</td>\n",
       "      <td>0.186467</td>\n",
       "      <td>0.094218</td>\n",
       "      <td>0.107899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113723</th>\n",
       "      <td>0.104654</td>\n",
       "      <td>0.011008</td>\n",
       "      <td>0.105099</td>\n",
       "      <td>0.284239</td>\n",
       "      <td>0.019194</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.028712</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.018270</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>0.374174</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>0.044602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53240 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          class0    class1    class2    class3    class4    class5    class6  \\\n",
       "id                                                                             \n",
       "151807  0.021627  0.023334  0.065777  0.124921  0.044512  0.000417  0.048683   \n",
       "118131  0.001412  0.063774  0.112211  0.138676  0.087546  0.000054  0.055819   \n",
       "110921  0.008781  0.060230  0.217216  0.181244  0.162623  0.001515  0.042537   \n",
       "105149  0.006011  0.134851  0.149127  0.139214  0.131760  0.000134  0.078139   \n",
       "143868  0.085706  0.142549  0.124000  0.116376  0.091587  0.000119  0.084573   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "146316  0.015957  0.115297  0.093594  0.102673  0.103073  0.000134  0.077883   \n",
       "121816  0.155807  0.013082  0.351903  0.129099  0.191808  0.000986  0.004530   \n",
       "106217  0.039621  0.199656  0.211499  0.118088  0.196356  0.000051  0.057648   \n",
       "103515  0.091429  0.055700  0.058322  0.106148  0.045634  0.000017  0.076015   \n",
       "113723  0.104654  0.011008  0.105099  0.284239  0.019194  0.000012  0.028712   \n",
       "\n",
       "          class7    class8    class9   class10   class11   class12  \n",
       "id                                                                  \n",
       "151807  0.051649  0.077450  0.074571  0.275773  0.032790  0.158495  \n",
       "118131  0.417896  0.052942  0.036014  0.018985  0.009312  0.005359  \n",
       "110921  0.167549  0.043226  0.035115  0.053229  0.013571  0.013165  \n",
       "105149  0.203856  0.063280  0.042052  0.021489  0.023419  0.006669  \n",
       "143868  0.008571  0.060298  0.067366  0.098988  0.085695  0.034170  \n",
       "...          ...       ...       ...       ...       ...       ...  \n",
       "146316  0.078376  0.081684  0.133270  0.072542  0.088998  0.036518  \n",
       "121816  0.000187  0.002742  0.004093  0.133633  0.007107  0.005022  \n",
       "106217  0.009684  0.031820  0.034603  0.031910  0.063821  0.005244  \n",
       "103515  0.004094  0.070956  0.103100  0.186467  0.094218  0.107899  \n",
       "113723  0.000441  0.018270  0.006975  0.374174  0.002620  0.044602  \n",
       "\n",
       "[53240 rows x 13 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit = pd.concat([\n",
    "    y_submit.reset_index(),\n",
    "    df_submit\n",
    "], axis=1)\n",
    "\n",
    "df_submit = df_submit.set_index('id')\n",
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_submit = pd.concat([\n",
    "#     y_submit.reset_index(),\n",
    "#     df_submit\n",
    "# ], axis=1)\n",
    "\n",
    "# df_submit = df_submit.set_index('id')\n",
    "# df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv('004_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
